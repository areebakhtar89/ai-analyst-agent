{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589df74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token detected. Testing chat completion...\n",
      "Model response:\n",
      "Yes, I can generate SQL and Python code. I can assist with:\n",
      "\n",
      "1. SQL:\n",
      "\t* Creating tables and indexes\n",
      "\t* Writing SELECT, INSERT, UPDATE, and DELETE queries\n",
      "\t* Joining tables and performing subqueries\n",
      "\t* Aggregating data and using grouping functions\n",
      "\t* Creating views, stored procedures, and functions\n",
      "2. Python:\n",
      "\t* General programming concepts (variables, data types, control structures, functions, etc.)\n",
      "\t* Data structures (lists, dictionaries, sets, etc.)\n",
      "\t* File input/output and persistence\n",
      "\t* Object-Oriented Programming (OOP) concepts\n",
      "\t* Working with popular libraries and frameworks (e.g., Pandas, NumPy, Flask, Django)\n",
      "\t* Data analysis, machine learning, and data science tasks\n",
      "\n",
      "Please let me know what specific task or problem you need help with, and I'll do my best to provide you with high-quality SQL and Python code.\n",
      "\n",
      "What do you need help with? Do you have a:\n",
      "\n",
      "1. Specific SQL query or database schema you'd like me to help with?\n",
      "2. Python project or task you're working on and need assistance with?\n",
      "3. General question about SQL or Python syntax and concepts?\n",
      "\n",
      "Let me know, and I'll be happy to help!\n",
      "\n",
      "SUCCESS: Token and model access working.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "\n",
    "if not HF_TOKEN:\n",
    "    raise ValueError(\"HF_TOKEN not found\")\n",
    "\n",
    "print(\"Token detected. Testing chat completion...\")\n",
    "\n",
    "try:\n",
    "    client = InferenceClient(\n",
    "        model=\"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "        token=HF_TOKEN,\n",
    "        provider=\"auto\",\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"What is your name? and how many parameters are you trained upn\"}\n",
    "        ],\n",
    "        max_tokens=2000,\n",
    "    )\n",
    "\n",
    "    print(\"Model response:\")\n",
    "    print(response.choices[0].message.content)\n",
    "    print(\"\\nSUCCESS: Token and model access working.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"\\nERROR:\")\n",
    "    print(str(e))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
